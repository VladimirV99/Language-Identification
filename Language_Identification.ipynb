{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05d045d2",
   "metadata": {
    "id": "05d045d2"
   },
   "source": [
    "# Language Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b80288",
   "metadata": {
    "id": "f4b80288"
   },
   "source": [
    "- https://arxiv.org/pdf/1701.03682.pdf\n",
    "- https://cs229.stanford.edu/proj2015/324_report.pdf\n",
    "- https://cs229.stanford.edu/proj2015/324_poster.pdf\n",
    "- https://sites.google.com/view/vardial2021/home\n",
    "- http://ttg.uni-saarland.de/resources/DSLCC/\n",
    "- https://mzampieri.com/publications.html\n",
    "- https://mzampieri.com/papers/dsl2016.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62993a6e",
   "metadata": {
    "id": "62993a6e"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b374c6",
   "metadata": {
    "id": "a6b374c6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9a29b5",
   "metadata": {},
   "source": [
    "## Make workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2016c824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directories if they don't exist\n",
    "os.makedirs(os.path.join('datasets/DSLCC-v2.0'), exist_ok=True)\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir('models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f536ba6",
   "metadata": {
    "id": "9f536ba6"
   },
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd806e0",
   "metadata": {},
   "source": [
    "We use the [DSLCC v2.0](https://github.com/alvations/bayesmax/tree/master/bayesmax/data/DSLCC-v2.0) dataset from the [DSL Shared Task 2015](http://ttg.uni-saarland.de/lt4vardial2015/dsl.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844d75c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "844d75c0",
    "outputId": "25c0cb59-a60d-417f-89cd-bc1c0515bee7"
   },
   "outputs": [],
   "source": [
    "# DSLCC v2.0\n",
    "if not os.path.exists('datasets/DSLCC-v2.0/train.txt'):\n",
    "    !cd datasets/DSLCC-v2.0 && curl -o train.txt https://raw.githubusercontent.com/alvations/bayesmax/master/bayesmax/data/DSLCC-v2.0/train-dev/train.txt\n",
    "if not os.path.exists('datasets/DSLCC-v2.0/devel.txt'):\n",
    "    !cd datasets/DSLCC-v2.0 && curl -o devel.txt https://raw.githubusercontent.com/alvations/bayesmax/master/bayesmax/data/DSLCC-v2.0/train-dev/devel.txt\n",
    "if not os.path.exists('datasets/DSLCC-v2.0/test.txt'):\n",
    "    !cd datasets/DSLCC-v2.0 && curl -o test.txt https://raw.githubusercontent.com/alvations/bayesmax/master/bayesmax/data/DSLCC-v2.0/test/test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9596f314",
   "metadata": {
    "id": "9596f314"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce00216",
   "metadata": {
    "id": "6ce00216"
   },
   "source": [
    "The corpus contains 20,000 instances per language (18,000 training + 2,000 development). Each instance is an excerpt extracted from journalistic texts containing 20 to 100 tokens and tagged with the country of origin of the text. A list of languages and the corresponing codes is shown in the following table:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Group Name</th>\n",
    "        <th>Language Name</th>\n",
    "        <th>Language Code</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=2>South Eastern Slavic</td>\n",
    "        <td>Bulgarian</td>\n",
    "        <td>bg</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Macedonian</td>\n",
    "        <td>mk</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=3>South Western Slavic</td>\n",
    "        <td>Bosnian</td>\n",
    "        <td>bs</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Croatian</td>\n",
    "        <td>hr</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Serbian</td>\n",
    "        <td>sr</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=2>West-Slavic</td>\n",
    "        <td>Czech</td>\n",
    "        <td>cz</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Slovak</td>\n",
    "        <td>sk</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=2>Ibero-Romance (Spanish)</td>\n",
    "        <td>Peninsular Spanish</td>\n",
    "        <td>es-ES</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Argentinian Spanish</td>\n",
    "        <td>es-AR</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=2>Ibero-Romance (Portugese)</td>\n",
    "        <td>Brazilian Portugese</td>\n",
    "        <td>pt-BR</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>European Portugese</td>\n",
    "        <td>pt-PT</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=2>Astronesian</td>\n",
    "        <td>Indonesian</td>\n",
    "        <td>id</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Malay</td>\n",
    "        <td>my</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Other</td>\n",
    "        <td>Various Languages</td>\n",
    "        <td>xx</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cbf165",
   "metadata": {
    "id": "d1cbf165"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('datasets/DSLCC-v2.0/train.txt', sep='\\t', names=['sentence', 'language'])\n",
    "validation = pd.read_csv('datasets/DSLCC-v2.0/devel.txt', sep='\\t', names=['sentence', 'language'])\n",
    "test = pd.read_csv('datasets/DSLCC-v2.0/test.txt', sep='\\t', names=['sentence', 'language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23b8b96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a23b8b96",
    "outputId": "47a73370-3727-43e7-94ae-94e16dcb89eb"
   },
   "outputs": [],
   "source": [
    "print(f'Training set size:   {len(train)}')\n",
    "print(f'Validation set size: {len(validation)}')\n",
    "print(f'Test set size:       {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9861f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b9861f8",
    "outputId": "8d70813c-58e6-476d-a380-f2eae66f5cc7"
   },
   "outputs": [],
   "source": [
    "# Print number of instances per label\n",
    "print(train['language'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e5b348",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['language'] == 'xx'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d6b558",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1d6b558",
    "outputId": "bdaa97f7-a120-4dbb-922d-4f6176761ce4"
   },
   "outputs": [],
   "source": [
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b2105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO use CLASSES with OneHotEncoder and CLASS_NAMES for output\n",
    "CLASS_UNKNOWN = 'xx'\n",
    "CLASSES = ['bg', 'mk', 'bs', 'hr', 'sr', 'cz', 'sk', 'es-ES', 'es-AR', 'pt-BR', 'pt-PT', 'id', 'my', CLASS_UNKNOWN]\n",
    "CLASS_NAMES = [\n",
    "    'Bulgarian', 'Macedonian', 'Bosnian', 'Croatian', 'Serbian', 'Czech', 'Slovak',\n",
    "    'Peninsular Spanish', 'Argentinian Spanish', 'Brazilian Portuguese', 'European Portuguese',\n",
    "    'Indonesian', 'Malay', 'Other'\n",
    "]\n",
    "NUM_CLASSES = len(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119869d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUM_CLASSES = len(train['language'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a4c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4139033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change all other language codes to xx\n",
    "def mark_unknown_languages(data):\n",
    "    data['language'].where([x in CLASSES for x in data['language']], CLASS_UNKNOWN, inplace=True)\n",
    "mark_unknown_languages(train)\n",
    "mark_unknown_languages(validation)\n",
    "mark_unknown_languages(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c28d50",
   "metadata": {
    "id": "c0c28d50"
   },
   "source": [
    "## Common preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e126d7",
   "metadata": {
    "id": "72e126d7"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb2f53c",
   "metadata": {
    "id": "abb2f53c"
   },
   "outputs": [],
   "source": [
    "X_train = train['sentence']\n",
    "y_train = train['language']\n",
    "X_validation = validation['sentence']\n",
    "y_validation = validation['language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1d7bfe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8e1d7bfe",
    "outputId": "125cbb5d-b6fd-412d-d381-55e08ccf036e"
   },
   "outputs": [],
   "source": [
    "print(X_train.head())\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0d2f11",
   "metadata": {
    "id": "0a0d2f11"
   },
   "outputs": [],
   "source": [
    "# y_train = pd.get_dummies(y_train).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f2e949",
   "metadata": {
    "id": "b6f2e949",
    "outputId": "d8a7b338-5643-47a4-df7a-667d55f77b93"
   },
   "outputs": [],
   "source": [
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db32a454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8830035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use OneHotEncoder for target variable\n",
    "# this is better than get_dummies because here we specify all classes\n",
    "# so all possible classes will have a column and the order will be specified\n",
    "# if the language code is unkown, an error is thrown\n",
    "target_encoder = OneHotEncoder(sparse=False, dtype=np.int32)\n",
    "target_encoder.fit(np.array(CLASSES).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741cd0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoder.transform(np.asarray(y_train[30000:30010]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8ac682",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa80e01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, GRU, Dropout, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133723f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape, hidden_layer_size, droupout_rate): #, recurrent_droupout_rate=0, dropout_rate=0, use_lstm=False):\n",
    "    # TODO Test with LSTM instead of GRU\n",
    "    # TODO Test with dropout after hidden layer\n",
    "    model = Sequential([\n",
    "        InputLayer(input_shape=input_shape),\n",
    "        GRU(hidden_layer_size, recurrent_dropout=dropout_rate),\n",
    "        # Dropout(rate=dropout_rate),\n",
    "        Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934cdf8e",
   "metadata": {
    "id": "934cdf8e"
   },
   "source": [
    "## Character n-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf06022d",
   "metadata": {
    "id": "cf06022d"
   },
   "source": [
    "## Word unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd06e20",
   "metadata": {
    "id": "7dd06e20"
   },
   "source": [
    "## Hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b9fae",
   "metadata": {
    "id": "4b7b9fae"
   },
   "source": [
    "## Ensemble"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Language_Identification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
