{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05d045d2",
   "metadata": {
    "id": "05d045d2"
   },
   "source": [
    "# Language Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b80288",
   "metadata": {
    "id": "f4b80288"
   },
   "source": [
    "- https://arxiv.org/pdf/1701.03682.pdf\n",
    "- https://cs229.stanford.edu/proj2015/324_report.pdf\n",
    "- https://cs229.stanford.edu/proj2015/324_poster.pdf\n",
    "- https://sites.google.com/view/vardial2021/home\n",
    "- http://ttg.uni-saarland.de/resources/DSLCC/\n",
    "- https://mzampieri.com/publications.html\n",
    "- https://mzampieri.com/papers/dsl2016.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62993a6e",
   "metadata": {
    "id": "62993a6e"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6b374c6",
   "metadata": {
    "id": "a6b374c6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9a29b5",
   "metadata": {},
   "source": [
    "## Make workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2016c824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directories if they don't exist\n",
    "os.makedirs(os.path.join('datasets/DSLCC-v2.0'), exist_ok=True)\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir('models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f536ba6",
   "metadata": {
    "id": "9f536ba6"
   },
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd806e0",
   "metadata": {},
   "source": [
    "We use the [DSLCC v2.0](https://github.com/alvations/bayesmax/tree/master/bayesmax/data/DSLCC-v2.0) dataset from the [DSL Shared Task 2015](http://ttg.uni-saarland.de/lt4vardial2015/dsl.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "844d75c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "844d75c0",
    "outputId": "25c0cb59-a60d-417f-89cd-bc1c0515bee7"
   },
   "outputs": [],
   "source": [
    "# DSLCC v2.0\n",
    "if not os.path.exists('datasets/DSLCC-v2.0/train.txt'):\n",
    "    !cd datasets/DSLCC-v2.0 && curl -o train.txt https://raw.githubusercontent.com/alvations/bayesmax/master/bayesmax/data/DSLCC-v2.0/train-dev/train.txt\n",
    "if not os.path.exists('datasets/DSLCC-v2.0/devel.txt'):\n",
    "    !cd datasets/DSLCC-v2.0 && curl -o devel.txt https://raw.githubusercontent.com/alvations/bayesmax/master/bayesmax/data/DSLCC-v2.0/train-dev/devel.txt\n",
    "if not os.path.exists('datasets/DSLCC-v2.0/test.txt'):\n",
    "    !cd datasets/DSLCC-v2.0 && curl -o test.txt https://raw.githubusercontent.com/alvations/bayesmax/master/bayesmax/data/DSLCC-v2.0/test/test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9596f314",
   "metadata": {
    "id": "9596f314"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce00216",
   "metadata": {
    "id": "6ce00216"
   },
   "source": [
    "The corpus contains 20,000 instances per language (18,000 training + 2,000 development). Each instance is an excerpt extracted from journalistic texts containing 20 to 100 tokens and tagged with the country of origin of the text. A list of languages and the corresponing codes is shown in the following table:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Group Name</th>\n",
    "        <th>Language Name</th>\n",
    "        <th>Language Code</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=2>South Eastern Slavic</td>\n",
    "        <td>Bulgarian</td>\n",
    "        <td>bg</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Macedonian</td>\n",
    "        <td>mk</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=3>South Western Slavic</td>\n",
    "        <td>Bosnian</td>\n",
    "        <td>bs</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Croatian</td>\n",
    "        <td>hr</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Serbian</td>\n",
    "        <td>sr</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=2>West-Slavic</td>\n",
    "        <td>Czech</td>\n",
    "        <td>cz</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Slovak</td>\n",
    "        <td>sk</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=2>Ibero-Romance (Spanish)</td>\n",
    "        <td>Peninsular Spanish</td>\n",
    "        <td>es-ES</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Argentinian Spanish</td>\n",
    "        <td>es-AR</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=2>Ibero-Romance (Portugese)</td>\n",
    "        <td>Brazilian Portugese</td>\n",
    "        <td>pt-BR</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>European Portugese</td>\n",
    "        <td>pt-PT</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=2>Astronesian</td>\n",
    "        <td>Indonesian</td>\n",
    "        <td>id</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Malay</td>\n",
    "        <td>my</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Other</td>\n",
    "        <td>Various Languages</td>\n",
    "        <td>xx</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1cbf165",
   "metadata": {
    "id": "d1cbf165"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('datasets/DSLCC-v2.0/train.txt', sep='\\t', names=['sentence', 'language'])\n",
    "validation = pd.read_csv('datasets/DSLCC-v2.0/devel.txt', sep='\\t', names=['sentence', 'language'])\n",
    "test = pd.read_csv('datasets/DSLCC-v2.0/test.txt', sep='\\t', names=['sentence', 'language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a23b8b96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a23b8b96",
    "outputId": "47a73370-3727-43e7-94ae-94e16dcb89eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size:   236135\n",
      "Validation set size: 26335\n",
      "Test set size:       13229\n"
     ]
    }
   ],
   "source": [
    "print(f'Training set size:   {len(train)}')\n",
    "print(f'Validation set size: {len(validation)}')\n",
    "print(f'Test set size:       {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b9861f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b9861f8",
    "outputId": "8d70813c-58e6-476d-a380-f2eae66f5cc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es-ES    17990\n",
      "es-AR    17808\n",
      "sr       17442\n",
      "pt-PT    17284\n",
      "id       17195\n",
      "mk       17154\n",
      "bg       17151\n",
      "xx       16920\n",
      "bs       16858\n",
      "hr       16792\n",
      "pt-BR    16483\n",
      "cz       16454\n",
      "sk       16224\n",
      "my       14380\n",
      "Name: language, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print number of instances per label\n",
    "print(train['language'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92e5b348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>219215</th>\n",
       "      <td>Любые действия, направленные на инаугурацию Ви...</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219216</th>\n",
       "      <td>Если мы посмотрим на то, как государство начин...</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219217</th>\n",
       "      <td>Ko sem letos po dolgih letih spet stala na vrh...</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219218</th>\n",
       "      <td>Данный центр, расположенный в Эдинбурге (Шотла...</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219219</th>\n",
       "      <td>Ito ang paniniwala ni Iloilo Rep. Niel Tupas J...</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sentence language\n",
       "219215  Любые действия, направленные на инаугурацию Ви...       xx\n",
       "219216  Если мы посмотрим на то, как государство начин...       xx\n",
       "219217  Ko sem letos po dolgih letih spet stala na vrh...       xx\n",
       "219218  Данный центр, расположенный в Эдинбурге (Шотла...       xx\n",
       "219219  Ito ang paniniwala ni Iloilo Rep. Niel Tupas J...       xx"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['language'] == 'xx'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1d6b558",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1d6b558",
    "outputId": "bdaa97f7-a120-4dbb-922d-4f6176761ce4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence language\n",
      "0  Зад думите “просто искам да се махна от Българ...       bg\n",
      "1  Сега нещата там леко потръгнаха с усилията на ...       bg\n",
      "2  Хърватският филм \"Пътят на дините\" на режисьор...       bg\n",
      "3  Министърът на правосъдието на РС Джерард Селма...       bg\n",
      "4  В крайна сметка войната между Севера и Юга дов...       bg\n"
     ]
    }
   ],
   "source": [
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12b2105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_UNKNOWN = 'xx'\n",
    "CLASSES = ['bg', 'mk', 'bs', 'hr', 'sr', 'cz', 'sk', 'es-ES', 'es-AR', 'pt-BR', 'pt-PT', 'id', 'my', CLASS_UNKNOWN]\n",
    "CLASS_NAMES = [\n",
    "    'Bulgarian', 'Macedonian', 'Bosnian', 'Croatian', 'Serbian', 'Czech', 'Slovak',\n",
    "    'Peninsular Spanish', 'Argentinian Spanish', 'Brazilian Portuguese', 'European Portuguese',\n",
    "    'Indonesian', 'Malay', 'Other'\n",
    "]\n",
    "NUM_CLASSES = len(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6a4c6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4139033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change all other language codes to xx\n",
    "def mark_unknown_languages(data):\n",
    "    data['language'].where([x in CLASSES for x in data['language']], CLASS_UNKNOWN, inplace=True)\n",
    "mark_unknown_languages(train)\n",
    "mark_unknown_languages(validation)\n",
    "mark_unknown_languages(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c28d50",
   "metadata": {
    "id": "c0c28d50"
   },
   "source": [
    "## Common preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72e126d7",
   "metadata": {
    "id": "72e126d7"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abb2f53c",
   "metadata": {
    "id": "abb2f53c"
   },
   "outputs": [],
   "source": [
    "X_train = train['sentence']\n",
    "y_train = train['language']\n",
    "X_validation = validation['sentence']\n",
    "y_validation = validation['language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e1d7bfe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8e1d7bfe",
    "outputId": "125cbb5d-b6fd-412d-d381-55e08ccf036e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Зад думите “просто искам да се махна от Българ...\n",
      "1    Сега нещата там леко потръгнаха с усилията на ...\n",
      "2    Хърватският филм \"Пътят на дините\" на режисьор...\n",
      "3    Министърът на правосъдието на РС Джерард Селма...\n",
      "4    В крайна сметка войната между Севера и Юга дов...\n",
      "Name: sentence, dtype: object\n",
      "0    bg\n",
      "1    bg\n",
      "2    bg\n",
      "3    bg\n",
      "4    bg\n",
      "Name: language, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train.head())\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db32a454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8830035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(dtype=&lt;class &#x27;numpy.int32&#x27;&gt;, sparse=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(dtype=&lt;class &#x27;numpy.int32&#x27;&gt;, sparse=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(dtype=<class 'numpy.int32'>, sparse=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use OneHotEncoder for target variable\n",
    "# this is better than get_dummies because here we specify all classes\n",
    "# so all possible classes will have a column and the order will be specified\n",
    "# if the language code is unkown, an error is thrown\n",
    "target_encoder = OneHotEncoder(sparse=False, dtype=np.int32)\n",
    "target_encoder.fit(np.array(CLASSES).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "741cd0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_encoder.transform(np.asarray(y_train[30000:30010]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb86368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create, configure and train a tokenizer \n",
    "def get_tokenizer(data, num_words=None):\n",
    "    tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n“„”–', num_words=num_words, oov_token='<OOV>')\n",
    "    tokenizer.fit_on_texts(data)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e90af97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim and pad data\n",
    "def preprocess_data(X, y, max_length=None):\n",
    "    if max_length is not None:\n",
    "        y = y[[len(x)<=max_length for x in X]]\n",
    "        X = [x for x in X if len(x)<=max_length]\n",
    "    X = pad_sequences(X, padding='post')\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8ac682",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa80e01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, LSTM, GRU, Dropout, Dense\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84804a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "133723f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape, hidden_layer_size, recurrent_dropout_rate=0.0, dropout_rate=0.0, use_lstm=False):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=input_shape))\n",
    "    if use_lstm:\n",
    "        model.add(LSTM(hidden_layer_size, recurrent_dropout=recurrent_dropout_rate, name='lstm'))\n",
    "    else:\n",
    "        model.add(GRU(hidden_layer_size, recurrent_dropout=recurrent_dropout_rate, name='gru'))\n",
    "    model.add(Dropout(rate=dropout_rate, name='dropout'))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax', name='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e386995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model training history\n",
    "def plot_history(history):\n",
    "    plt.plot(history.epoch, history.history['accuracy'])\n",
    "    plt.plot(history.epoch, history.history['val_accuracy'])\n",
    "    plt.legend(['Training accuracy', 'Validation accuracy'])\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xticks(history.epoch, np.arange(1, len(history.epoch)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ced32a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model, compilation and training data and history plot\n",
    "def save_model(model, batch_size, history, model_name=None):\n",
    "    recurrent_layer = model.get_layer(index=0)\n",
    "    recurrent_type = recurrent_layer.name\n",
    "    recurrent_units = recurrent_layer.units\n",
    "    recurrent_dropout_rate = recurrent_layer.recurrent_dropout\n",
    "    \n",
    "    dropout_layer = model.get_layer(index=1)\n",
    "    dropout_rate = dropout_layer.rate\n",
    "\n",
    "    epochs = len(history.epoch)\n",
    "    \n",
    "    if not model_name:\n",
    "        model_name = f'model_{epochs}_{batch_size}_{recurrent_type}_{recurrent_units}_{int(100*recurrent_dropout_rate)}_{int(100*dropout_rate)}_{time.strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "    model_path = f'models/{model_name}'\n",
    "    \n",
    "    model.save(model_path)\n",
    "    with open(f'{model_path}/training.txt', 'w') as f:\n",
    "        f.write(f'EPOCHS:            \\t {epochs}\\n')\n",
    "        f.write(f'BATCH SIZE:        \\t {batch_size}\\n')\n",
    "        f.write(f'RECURRENT LAYER:   \\t {recurrent_type}\\n')\n",
    "        f.write(f'RECURRENT UNITS:   \\t {recurrent_units}\\n')\n",
    "        f.write(f'RECURRENT DROPOUT: \\t {recurrent_dropout_rate}\\n')\n",
    "        f.write(f'OUTPUT DROPOUT:    \\t {dropout_rate}\\n')\n",
    "        model.summary(print_fn = lambda x: f.write(x + '\\n'))\n",
    "        f.write(f'ACCURACY:     \\t {history.history[\"accuracy\"]}\\n')\n",
    "        f.write(f'VAL ACCURACY: \\t {history.history[\"val_accuracy\"]}\\n')\n",
    "    plot_history(history)\n",
    "    plt.title(model_name)\n",
    "    plt.savefig(f'{model_path}/history.png')\n",
    "    return model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76e3fda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, input_sequences, vocabulary_size, labels, batch_size=32, shuffle=True):\n",
    "        self.input_sequences = input_sequences\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        # TODO move to __getitem__\n",
    "        self.labels = target_encoder.transform(np.asarray(labels).reshape(-1, 1))\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        # TODO check does this get called automatically anyway\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    # Number of batches per epoch\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.input_sequences) / self.batch_size))\n",
    "\n",
    "    # Generate one batch\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        X = to_categorical([self.input_sequences[index] for index in indexes], num_classes=self.vocabulary_size)\n",
    "        # y = target_encoder.transform(np.asarray([labels[index] for index in indexes]).reshape(-1, 1))\n",
    "        y = np.asarray([self.labels[index] for index in indexes])\n",
    "        return X, y\n",
    "\n",
    "    # Update indexes for next epoch\n",
    "    def on_epoch_end(self):\n",
    "        # TODO move to __init__, there is no need to re-arange indexes each epoch\n",
    "        # they will either always or never be shuffled\n",
    "        self.indexes = np.arange(len(self.input_sequences))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6b4c6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictGenerator(Sequence):\n",
    "    def __init__(self, input_sequences, vocabulary_size, batch_size=32):\n",
    "        self.input_sequences = input_sequences\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    # Number of batches per epoch\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.input_sequences) / self.batch_size))\n",
    "\n",
    "    # Generate one batch\n",
    "    def __getitem__(self, index):\n",
    "        indexes = np.arange(index*self.batch_size, min((index+1)*self.batch_size, len(self.input_sequences)))\n",
    "        X = to_categorical([self.input_sequences[index] for index in indexes], num_classes=self.vocabulary_size)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934cdf8e",
   "metadata": {
    "id": "934cdf8e"
   },
   "source": [
    "## Character n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cb2b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from nltk.util import ngrams\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00d39768",
   "metadata": {},
   "outputs": [],
   "source": [
    "NGRAMS_MAX_WORDS = {\n",
    "    2: None,\n",
    "    3: 20000,\n",
    "    4: None,\n",
    "    5: None\n",
    "}\n",
    "\n",
    "def sentence_to_char_ngram(sentence, n):\n",
    "    s = ''.join([c if c not in '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n“„”–' else ' ' for c in sentence])\n",
    "    tokens = text_to_word_sequence(s)\n",
    "    ngrams_ = [[''.join(ng) for ng in list(ngrams(token, n))] for token in tokens if len(token) >= n]\n",
    "    return ' '.join(chain.from_iterable(ngrams_))\n",
    "\n",
    "def transform_to_char_ngrams(X, n):\n",
    "    X_ngram_train = X.copy()\n",
    "    print(f'{n} - gramming')\n",
    "    return X_ngram_train.progress_apply(lambda sentence: sentence_to_char_ngram(sentence, n))\n",
    "\n",
    "def get_char_ngram_tokenizer(X, n):\n",
    "  tokenizer = get_tokenizer(X, num_words=NGRAMS_MAX_WORDS[n])\n",
    "  return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd3f58b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lengths = {2: 150, 3: 150}\n",
    "def prepare_n_gram_model(n):\n",
    "  X_ngram_train_initial = transform_to_char_ngrams(X_train, n)\n",
    "  n_tokenizer = get_char_ngram_tokenizer(X_ngram_train_initial, n)\n",
    "  X_ngram_train_tokenized = n_tokenizer.texts_to_sequences(X_ngram_train_initial)\n",
    "  X_ngram_train, y_ngram_train = preprocess_data(X_ngram_train_tokenized, y_train, max_length=max_lengths[n])\n",
    "\n",
    "  print(f'')\n",
    "\n",
    "  n_model = get_model((X_ngram_train.shape[1], len(n_tokenizer.word_counts.keys())), hidden_layer_size=1024, dropout_rate=0.45)\n",
    "  def train_model():\n",
    "    history = n_model.fit(\n",
    "      DataGenerator(X_ngram_train, len(n_tokenizer.word_counts.keys()), y_ngram_train, BATCH_SIZE),\n",
    "#     validation_data=validation_generator,\n",
    "      epochs=EPOCHS,    # callbacks=[checkpoint_callback]\n",
    "    )\n",
    "    return history\n",
    "\n",
    "  return n_model, train_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77834d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 - gramming\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 236135/236135 [00:19<00:00, 12030.28it/s]\n"
     ]
    }
   ],
   "source": [
    "_, train_2 = prepare_n_gram_model(2)\n",
    "\n",
    "history_2 = train_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf06022d",
   "metadata": {
    "id": "cf06022d"
   },
   "source": [
    "## Word unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d74fbdf",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37dd3c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_UNIQUE_WORDS = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "28537c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_w1 = get_tokenizer(X_train, NUM_UNIQUE_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6713881",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer_w1.texts_to_sequences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cddb52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find max word dict index\n",
    "max([max(x) for x in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea99f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find max length of train sequences\n",
    "max([len(x) for x in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9734679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = preprocess_data(X_train, y_train, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ac0ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9077cd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_w1.num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4883f930",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef8ff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenizer_w1.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1bb2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_w1.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503ccb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x for x in tokenizer_w1.word_counts.items() if x[1] > 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc3098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(tokenizer_w1.word_counts.items(), key=lambda w: w[1], reverse=False)[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b58f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb71462",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83655303",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e6e9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_generator = DataGenerator(X_train, tokenizer_w1.num_words, y_train, batch_size=BATCH_SIZE)\n",
    "# validation_generator = DataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aecbe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_model((X_train.shape[1], tokenizer_w1.num_words), HIDDEN_LAYER_SIZE, DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccc46cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     filepath='models/checkpoint',\n",
    "#     save_weights_only=True,\n",
    "#     monitor='val_accuracy',\n",
    "#     mode='max',\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# history = model.fit(\n",
    "#     train_generator,\n",
    "# #     validation_data=validation_generator,\n",
    "#     epochs=EPOCHS,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     callbacks=[checkpoint_callback]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f429b192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model(model, BATCH_SIZE, history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd06e20",
   "metadata": {
    "id": "7dd06e20"
   },
   "source": [
    "## Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2166496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de64fa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_model(devel_X_processor=lambda x: x):\n",
    "    X = devel_X_processor(X_validation.copy())\n",
    "\n",
    "    devel_train_X, devel_test_X, devel_train_Y, devel_test_Y = train_test_split(\n",
    "        X, y_validation, train_size=0.75, stratify=y_validation\n",
    "    )\n",
    "\n",
    "    tokenizer = get_tokenizer(devel_train_X, 10_000)\n",
    "    \n",
    "    devel_train_X = tokenizer.texts_to_sequences(devel_train_X)\n",
    "    devel_test_X = tokenizer.texts_to_sequences(devel_test_X)\n",
    "\n",
    "    devel_train_X, devel_train_Y = preprocess_data(devel_train_X, devel_train_Y, 50)\n",
    "    devel_test_X, devel_test_Y = preprocess_data(devel_test_X, devel_test_Y, 50)\n",
    "\n",
    "    recurrent_layer_sizes = [768, 1024, 1280]\n",
    "    dropout_rates = [0.2, 0.25, 0.35, 0.4, 0.45]\n",
    "    \n",
    "    results_acc = [[0 for _ in range(len(dropout_rates))] for _ in range(len(recurrent_layer_sizes))]\n",
    "    results_val_acc = [[0 for _ in range(len(dropout_rates))] for _ in range(len(recurrent_layer_sizes))]\n",
    "\n",
    "    for i, recurrent_layer_size in enumerate(recurrent_layer_sizes):\n",
    "        for j, dropout_rate in enumerate(dropout_rates):\n",
    "#             if not (i == 0 and j == 0):\n",
    "#                 continue\n",
    "            print('Training network with params:')\n",
    "            print(f' - recurrent_layer_size = {recurrent_layer_size}')\n",
    "            print(f' - dropout_rate      = {dropout_rate}')\n",
    "            \n",
    "            devel_train_generator = DataGenerator(devel_train_X, tokenizer.num_words, devel_train_Y, batch_size=BATCH_SIZE)\n",
    "            devel_test_generator = DataGenerator(devel_test_X, tokenizer.num_words, devel_test_Y, batch_size=BATCH_SIZE)\n",
    "\n",
    "            model = get_model((devel_train_X.shape[1], tokenizer.num_words), recurrent_layer_size, dropout_rate)\n",
    "            history = model.fit(\n",
    "                devel_train_generator,\n",
    "                validation_data=devel_test_generator,\n",
    "                epochs=EPOCHS\n",
    "            )\n",
    "            model_name = save_model(model, BATCH_SIZE, history)\n",
    "      \n",
    "            results_acc[i][j] = history.history[\"accuracy\"]\n",
    "            results_val_acc[i][j] = history.history[\"val_accuracy\"]\n",
    "            print(f'Results for {hidden_layer_size}, {dropout_rate} ({i}, {j}):')\n",
    "            print(f'accuracy:     {history.history[\"accuracy\"]}')\n",
    "            print(f'val_accuracy: {history.history[\"val_accuracy\"]}')\n",
    "\n",
    "    grid_search_results_acc_df = pd.DataFrame(results_acc, index=recurrent_layer_sizes, columns=dropout_rates)\n",
    "    grid_search_results_val_acc_df = pd.DataFrame(results_val_acc, index=recurrent_layer_sizes, columns=dropout_rates)\n",
    "    grid_search_results_acc_df.to_csv('grid_search_acc.csv')\n",
    "    grid_search_results_val_acc_df.to_csv('grid_search_acc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec995dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc5fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "recurrent_layer_sizes = [768, 1024, 1280]\n",
    "dropout_rates = [0.2, 0.25, 0.35, 0.4, 0.45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173f8a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_val_acc = np.asarray([\n",
    "    [0.8253777623176575, 0.8014002442359924, 0.838083803653717,  0.8221153616905212, 0.8358948230743408],\n",
    "    [0.8248626589775085, 0.8288934230804443, 0.8365384340286255, 0.8264079689979553, 0.8384562730789185],\n",
    "    [0.8257211446762085, 0.8265796899795532, 0.8123282790184021, 0.8094093203544617, 0.8167691230773926]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaf9d61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(grid_search_val_acc)\n",
    "plt.colorbar()\n",
    "plt.yticks(np.arange(len(recurrent_layer_sizes)), recurrent_layer_sizes)\n",
    "plt.xticks(np.arange(len(dropout_rates)), dropout_rates)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7090732",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = np.argmax(grid_search_val_acc)\n",
    "best_recurrent_layer_size = recurrent_layer_sizes[best_score // len(dropout_rates)]\n",
    "best_dropout = dropout_rates[best_score % len(dropout_rates)]\n",
    "print(best_score)\n",
    "print(best_recurrent_layer_size)\n",
    "print(best_dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7b9fae",
   "metadata": {
    "id": "4b7b9fae"
   },
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e71fd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9a6cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_model, X_val_model, y_train_model, y_val_model = train_test_split(\n",
    "    X_train, y_train, train_size=0.9, stratify=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23bdcf2",
   "metadata": {},
   "source": [
    "### Word unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e4d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_w1 = get_tokenizer(X_train_model, 10_000)\n",
    "\n",
    "X_train_model = tokenizer_w1.texts_to_sequences(X_train_model)\n",
    "X_val_model = tokenizer_w1.texts_to_sequences(X_val_model)\n",
    "\n",
    "X_train_model, y_train_model = preprocess_data(X_train_model, y_train_model, 50)\n",
    "X_val_model, y_val_model = preprocess_data(X_val_model, y_val_model, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bf03e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "model_w1 = get_model((X_train_model.shape[1], tokenizer_w1.num_words), best_recurrent_layer_size, best_dropout)\n",
    "history_w1 = model_w1.fit(\n",
    "    DataGenerator(X_train_model, tokenizer_w1.num_words, y_train_model, batch_size=BATCH_SIZE),\n",
    "    validation_data=DataGenerator(X_val_model, tokenizer_w1.num_words, y_val_model, batch_size=BATCH_SIZE),\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "save_model(model_w1, BATCH_SIZE, history_w1, model_name='model_w1_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96f88f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model_w1\n",
    "# model_w1 = load_model('models/model_w1_final')\n",
    "# model_w1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8115e679",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_w1 = model_w1.predict(PredictGenerator(X_val_model, tokenizer_w1.num_words, batch_size=BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b386647e",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8ec228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine outputs\n",
    "# TODO add other models\n",
    "# X_ensemble = pd.DataFrame(np.hstack((output_w1, output_w1)))\n",
    "X_ensemble = pd.DataFrame(output_w1)\n",
    "y_ensemble = pd.Series(y_val_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133f0b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_ensemble))\n",
    "print(len(y_ensemble))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7ea88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_index = 3\n",
    "print(X_ensemble.iloc[example_index])\n",
    "print(y_ensemble.iloc[example_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efcbc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_ensemble.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647b61bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "N_SPLITS = 5\n",
    "kf = KFold(n_splits=N_SPLITS)\n",
    "\n",
    "for i, (train_indexes, test_indexes) in enumerate(kf.split(X_ensemble, y_ensemble)):\n",
    "    print(f'evaluating split {i+1} of {N_SPLITS}')\n",
    "    \n",
    "    X_ensemble_train = X_ensemble.iloc[train_indexes]\n",
    "    y_ensemble_train = y_ensemble.iloc[train_indexes]\n",
    "    \n",
    "    X_ensemble_val = X_ensemble.iloc[test_indexes]\n",
    "    y_ensemble_val = y_ensemble.iloc[test_indexes]\n",
    "    \n",
    "    ensemble = LogisticRegression()\n",
    "    ensemble.fit(X_ensemble_train, y_ensemble_train)\n",
    "    \n",
    "    score = ensemble.score(X_ensemble_val, y_ensemble_val)\n",
    "    \n",
    "    scores.append(score)\n",
    "    print(f'score: {score}')\n",
    "    \n",
    "print('all scores:')\n",
    "print(scores)\n",
    "print(f'average score: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f99e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = LogisticRegression()\n",
    "ensemble.fit(X_ensemble, y_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926b183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ensemble.predict(X_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa761e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8a9e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ensemble.coef_)\n",
    "print(ensemble.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c8354c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fb29a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_ensemble, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe15710",
   "metadata": {},
   "source": [
    "## Results"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Language_Identification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "79446e44ba6bee24089cb4961a028f7d7a9fa0f62042f6193d6d5842677d9fc7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
